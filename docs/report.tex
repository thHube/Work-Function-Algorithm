\documentclass[a4paper, 10pt]{article}

\usepackage[italian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\usepackage{amsmath}

\begin{document}
    \title{Relazione sull'implementazione dell'algoritmo \textsc{Work}}
    \author{\textsc{Alberto Franco, Mirko Polato, Lorenzo Tessari}}
    \maketitle

\section{Introduzione}    
L'algoritmo \textsc{Work} rappresenta un notevole risultato nella ricerca
legata al problema dei $k$-server. Questo algoritmo infatti permette di 
rispondere alle richieste del problema in modo $(2k - 1)$-competitivo che 
non è il limite inferiore ma ci si avvicina molto. 

Ci è stato chiesto di implementare questo algoritmo in modo efficiente, in 
questo documento presentiamo l'implementazione data. Il pezzo di software che 
è stato prodotto è stato scritto in C++ per la grande efficienza del 
linguaggio e la libertà che questo offre in termini di gestione delle risorse,
come la memoria, ad esempio.

\subsection{Struttura del progetto}
Il progetto è strutturato in questo modo: vi sono due cartelle all'interno della
principale \texttt{src} e \texttt{docs}. Questo documento è stato generato dal 
file \LaTeX contenuto nella cartella \texttt{docs}. L'altra cartella contiene 
tutti i sorgenti (\texttt{*.h, *.cpp}) dell'applicazione. Durante lo sviluppo
è stato utilizzato il sistema di gestione del progetto \emph{CMake} il cui
file di configurazione è all'interno della directory radice, nella stessa
cartella è presente un makefile per compilare l'applicazione. 

Il software è stato testato su Linux a 64 bit con il compilatore GCC e in 
ambiente Windows con compilatore Mingw GCC a 32 bit e Microsoft Visual C++
sia a 32 che a 64 bit.

\section{Sviluppo della applicazione}
In questa sezione descriveremo brevemente quali sono state le scelte di design
operate nell'implementare l'algoritmo. Rispetto ad una implementazione volta
solo ad ottenere efficienza si è preferito usare disegno (e conseguentemente
una programmazione) ad oggetti il più corretto possibile in modo da dare 
a chi usa la componente software una maggiore comprensione del modo in cui questa
funziona. 

Si è scelto di permettere agli utenti della 
classe \texttt{Configuration} di scorrere gli elementi della configurazione
tramite un iteratore invece che dare accesso diretto alla memoria sottostante.
Questo permette una gestione più elegante dell'iterazione di una configurazione
e successive modifiche nella gestione interna non modificherebbero il codice
utente già scritto. 

A scopo di test dell'algoritmo si è deciso di usare un generatore di richieste
casuali (la classe \texttt{RequestGenerator}) che genera in modo uniforme le 
richieste nell'intervallo $[-50, 50]$. L'utente può decidere al momento 
dell'avvio della applicazione la dimensione dello spazio in cui queste richieste
verranno generate. 

Nelle sotto sezioni successive verranno presentate le ottimizzazioni operate
per rendere l'esecuzione più veloce. 

\subsection{Paginazione della memoria}
La prima ottimizzazione che a nostro avviso era necessario operare risiede 
nell'ottimizzare l'uso della memoria al fine di evitare continue allocazioni e
deallocazioni. Notoriamente l'uso efficiente della memoria è fonte di grande
ottimizzazione all'interno delle applicazioni. Il metodo più semplice che 
ci è sembrato opportuno usare per sviluppare l'algoritmo è il \emph{caching}.
Al posto di allocare e deallocare gli oggetti che usiamo spesso (configurazioni
nel nostro caso) abbiamo deciso di usare e riciclare gli oggetti che già abbiamo.
A questo proposito la classe \texttt{ConfigurationFactory} si occupa di gestire
le copie di oggetti di tipo \texttt{Configuration} che abbiamo creato. 
Inizialmente configuration factory inizializza una pagina di memoria con 
un numero di oggetti da noi deciso e, ogni qualvolta gli venga richiesto un 
oggetto nuovo questa effettua la seguente operazione:
\begin{itemize}
  \item Se vi sono ancora oggetti disponibili sulla pagina di memoria correntemente
  allocata allora ritorna uno di quelli oggetti.
  \item Se gli oggetti sono tutti in uso allora alloca una nuova pagina di 
  memoria e ritorna un oggetto.
\end{itemize}
Questo avviene quando il metodo \texttt{create()} viene invocato. Una volta 
che l'oggetto è stato utilizzato esso deve venire riciclato tramite una 
chiamata a \texttt{recycle(Configuration*)} che reinserisce l'oggetto nello 
stack degli oggetti disponibili. \'E stato usato uno stack per favorire la 
località dei riferimenti, se un oggetto viene deallocato e poi un altro 
subito richiesto è probabile che questo resti in cache (o quanto meno il 
puntatore all'oggetto).

Una nota da fare è che la classe \texttt{ConfigurationFactory} è stata 
implementata seguendo il design pattern \emph{Singleton} per avere una sola
istanza della classe inoltre, il costruttore di \texttt{Configuration} è 
privato dunque si possono creare istanze di tale tipo solo attraverso la 
classe appena descritta. 

\subsection{Ottimizzazione della ricorsione}
Per ottimizzare il calcolo del server che deve rispondere ad ogni richiesta 
è stata operata la modifica all'algoritmo originale descritta nella sezione
``Dettagli implementativi'' della dispensa. Ad ogni richiesta viene associato
un limite superiore calcolato come $L_{sup} = w_{t - 1}(A_{t - 1}) + d(x_t, r_t)$ 
dove $x_t$ è il server correntemente in analisi e $w_{t - 1}(A_{t - 1})$ è il
costo pagato fino alla richiesta $t$-esima dall'algoritmo \textsc{Work}. Questo
costo viene aggiornato dopo aver processato ogni richiesta. 

Ad ogni iterazione della funzione lavoro viene verificata la disuguaglianza:
\[
  L_{sup} - \sum_{s = i + 1}^{t} d(y_s, r_s) \geq D(X_i, X_0)
\]
se questa non è verificata allora proseguiamo a verificare il prossimo elemento
senza scendere nelle chiamate ricorsive legate al calcolo di $w_i(A_i)$. Questo
permette di eliminare un buon numero di chiamate ricorsive a \texttt{work}. 

\section{Ulteriori Ottimizzazioni}
Una idea iniziale era di migliorare l'efficienza dell'algoritmo usando una 
finestra di dimensione $w$ controllando un numero costante di elementi 
ad ogni richiesta. In pratica la variazione dell'algoritmo (chiamato $\omega$-WFA) 
calcola la funzione lavoro all'iterazione $t$ partendo da $w_{\omega - t}$. Questa 
ottimizzazione è già stata proposta in \cite{baumgartner}. In tale articolo 
gli autori esibiscono una prova empirica del fatto che $\omega$-WFA preservi la 
competitività di \textsc{WORK}, tale prova poco accettabile a livello matematico
viene infatti smentita. Una prova della non-competitività di $\omega$-WFA è data in
\cite{rudec}. Qui ne presentiamo una versione ridotta. 

\newtheorem{noncomp}{Teorema} 
\begin{noncomp}
$\omega$-WFA non è $\alpha$-competitivo.
\end{noncomp}
\begin{proof}
Per il caso in cui $\omega = 1$ la dimostrazione è banale dato
che $1-$WFA è l'algoritmo \textsc{Greedy}. Ci limitiamo al caso $\omega \geq 2$.
Sulla base di queste assunzioni costruiamo uno scenario che ci permette di 
confutare la affermazione che $\omega$-WFA sia $\alpha$-competitivo. Il nostro 
scenario è composto da una ``isola'' composta da due locazioni $x_1$ e $x_2$ e 
da un ``entroterra'' in cui vi sono tutte le altre locazioni. Scegliamo una 
sequenza di richieste in modo siano localizzate alternativamente in $x_1$ e 
$x_2$, l'idea è che $\omega$-WFA muoverà solo i server sull'isola lasciando fermi 
quelli nell'entroterra. Per dimostrare questo dividiamo in due casi:
\begin{enumerate}
    \item $1 \leq i \leq \omega$. In questo caso la funzione lavoro si comporta in 
    modo canonico perciò in questa sezione l'algoritmo coincide con 
    \textsc{Work} 
    \item $i > \omega$. IN questa sezione l'algoritmo non tiene conto di tutte le 
    richieste ma considera $r_{t - \omega + 1}$ come la prima richiesta. In questo 
    caso l'algoritmo sceglie sempre una configurazione che muove solo i server 
    che sono nell'isola perché il costo pagato per queste è minore rispetto a 
    quella in cui un server dell'entroterra viene mosso sull'isola. 
\end{enumerate}
Se chiamiamo $\delta$ la distanza tra $x_1$ e $x_2$ e $\Delta$ la distanza tra 
$x_1$ e la prima locazione dell'entroterra allora per una sequenza di richieste
di lunghezza $n$ tale che $n > \Delta / \delta > \omega$ l'algoritmo diventa 
non-competitivo.
\end{proof}

Una supposizione ragionevole è che questa ottimizzazione non funzioni per spazi
metrici qualsiasi ma con le dovute restrizioni la competitività venga preservata.
In primo luogo considereremo uno spazio
metrico finito, la cui distanza massima è $\Delta$ inoltre consideriamo una
discretizzazione di questo spazio tale che la distanza minima tra le richieste
sia $\delta$. In generale queste assunzioni non sono limitanti dal momento che 
le implementazioni effettive sul calcolatore hanno intrinsecamente queste 
limitazioni.

La prima scelta che operiamo è la dimensione della finestra. 
Scegliamo $\omega > \Delta/\delta$ e $\omega > k$. Dove $k$ è il numero di 
server a disposizione\footnote{In generale un valore di $\omega$ ragionevole
è $\omega = \Delta / \delta + 1$}. 

Il nostro algoritmo andrà a calcolare la funzione lavoro esattamente nello 
stesso modo in cui viene calcolata nell'algoritmo \textsc{Work} con la 
differenza che alla richiesta $t$-esima:
\[
    work(t, A_t) = 
    \left\{ \begin{array}{l l}
        w_t(A_t) & \quad \text{se } t < \omega\\
        w_\omega(A_t) & \quad \text{se } t \geq \omega \\
    \end{array}\right.
\]
Andiamo ad effettuare una analisi all'esempio fornito
da \cite{rudec}. Supponiamo la nostra configurazione sia la stessa. Abbiamo una 
``isola'' composta dalle posizioni ammissibili $x_1, x_2$ in cui arrivano le 
richieste con un server nella posizione $x_1$ (intercambiabilmente in $x_2$) 
e un ``entroterra'' in cui vi sono tutti gli altri server a distanza $\Delta$. 
e supponiamo di aver scelto $\omega = \Delta / \delta + 1$ allora alle prime 
$\omega - 1$ richieste $\omega$-WFA paqherà un costo pari a $\delta \omega$ e 
poi alla $w$-esima sposta un server dall'entroterra pagando un costo totale 
$(\omega - 1)\delta + \Delta$ mentre OPT off-line paga un costo $\Delta$ 
partendo dalla stessa configurazione. Perciò comparando i costi otteniamo che 
\[
    \frac{(\omega - 1) \delta + \Delta}{\Delta} \leq (2k -1) \Rightarrow 
    2  \leq (2k - 1)
\]
Dunque in questo scenario l'algoritmo paga un costo inferiore a $(2k - 1)C_{OPT}$. 

\section{Conclusioni}
Passare dalla pura teoria a trovarsi di fronte a dover dare una implementazione 
effettiva di un algoritmo così complesso e con così forte ricadute teoriche 
non è un compito semplice. Inizialmente abbiamo dovuto ragionare su quali 
fossero le componenti necessarie e, dopo aver isolato quello di cui 
abbisognavamo abbiamo implementato il tutto. 

La scelta del C++ come linguaggio di implementazione è stata quasi ovvia. Una 
idea alternativa poteva essere Java ma questo non ci avrebbe permesso di 
gestire la memoria così come è stato fatto.  

\bibliographystyle{alpha}
\bibliography{ref}

\end{document}
